blueprint:
  name: Person Detected with AI and TTS (Reprocess with Configurable Delay)
  description: >
    Detect a person, analyze the image with AI, and announce the message using TTS. After a configurable delay (entered manually in seconds), reprocesses the image with a second set of configurable instructions.
  domain: automation
  input:
    trigger_sensor:
      name: Trigger Sensor
      description: Binary sensor to trigger the automation.
      selector:
        entity:
          domain: binary_sensor
    camera_entity:
      name: Camera Entity
      description: Camera entity for capturing images.
      selector:
        entity:
          domain: camera
    media_player_entity:
      name: Media Player Entity
      description: Media player for text-to-speech output.
      selector:
        entity:
          domain: media_player
    volume_level:
      name: Volume Level
      description: Volume level for the media player.
      default: 1
      selector:
        number:
          min: 0
          max: 1
          step: 0.1
          unit_of_measurement: "volume"
    image_instructions:
      name: Image Instructions
      description: >
        Instructions for the initial AI image analysis (e.g., describe the person and what they are doing).
      default: >
        In one sentence tell the person or persons in the camera, that you see
        them and give some indication of what they are wearing and what they
        are doing. Mention that they are trespassing and we will call the
        police. If nobody is detected, don't respond.
      selector:
        text:
          multiline: true
    after_30s_instructions:
      name: After Delay Instructions
      description: >
        Instructions for the AI image analysis after the configurable delay, regardless of sensor state.
      default: >
        Reanalyze the image and provide an update on what the person or persons are doing now.
      selector:
        text:
          multiline: true
    delay_duration:
      name: Delay Duration (Seconds)
      description: >
        Enter how many seconds to wait before reprocessing the image (0 to 120 seconds).
      default: 30
      selector:
        number:
          min: 0
          max: 120
          step: 1
trigger:
  - platform: state
    entity_id: !input trigger_sensor
    to: "on"
condition: []
action:
  - service: llmvision.image_analyzer
    data:
      provider: OpenAI
      model: gpt-4o
      include_filename: false
      target_width: 1280
      detail: high
      max_tokens: 221
      temperature: 0.5
      image_entity:
        - !input camera_entity
      message: !input image_instructions
    response_variable: response
  - service: media_player.volume_set
    target:
      entity_id: !input media_player_entity
    data:
      volume_level: !input volume_level
  - service: tts.google_cloud_say
    data:
      entity_id: !input media_player_entity
      message: "{{response.response_text}}"
      language: en-US
      options:
        gender: MALE
        voice: en-US-Casual-K
  - delay:
      seconds: !input delay_duration  # Delay based on manual input in seconds
  - service: llmvision.image_analyzer  # Reprocess the image after the delay
    data:
      provider: OpenAI
      model: gpt-4o
      include_filename: false
      target_width: 1280
      detail: high
      max_tokens: 221
      temperature: 0.5
      image_entity:
        - !input camera_entity
      message: !input after_30s_instructions
mode: single
