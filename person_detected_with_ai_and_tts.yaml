blueprint:
  name: Person Detected with AI and TTS (Reprocess with Two Configurable Instruction Sets)
  description: >
    Detect a person, analyze the image with AI, and announce the message using TTS.
    After a user-defined delay, reprocesses the image with a second set of configurable instructions
    without checking the sensor state again.
  domain: automation
  input:
    trigger_sensor:
      name: Trigger Sensor
      description: Binary sensor to trigger the automation.
      selector:
        entity:
          domain: binary_sensor
    camera_entity:
      name: Camera Entity
      description: Camera entity for capturing images.
      selector:
        entity:
          domain: camera
    media_player_entity:
      name: Media Player Entity
      description: Media player for text-to-speech output.
      selector:
        entity:
          domain: media_player
    volume_level:
      name: Volume Level
      description: Volume level for the media player.
      default: 1
      selector:
        number:
          min: 0
          max: 1
          step: 0.1
          unit_of_measurement: "volume"
    image_instructions:
      name: Image Instructions
      description: >
        Instructions for the initial AI image analysis (e.g., describe the person and what they are doing).
      default: >
        In one sentence tell the person or persons in the camera, that you see
        them and give some indication of what they are wearing and what they
        are doing. Mention that they are trespassing and we will call the
        police. If nobody is detected, don't respond.
      selector:
        text:
          multiline: true
    after_delay_instructions:
      name: After Delay Instructions
      description: >
        Instructions for the AI image analysis after the configurable delay, regardless of sensor state.
      default: >
        Reanalyze the image and provide an update on what the person or persons are doing now.
      selector:
        text:
          multiline: true
    delay_seconds:
      name: Delay Before Reprocessing (seconds)
      description: >
        Delay before reprocessing the image with the second set of instructions.
        Must be between 1 and 120 seconds.
      default: 30
      selector:
        number:
          min: 1
          max: 120
          mode: slider
          step: 1

trigger:
  - platform: state
    entity_id: !input trigger_sensor
    to: "on"

condition: []

action:
  - service: llmvision.image_analyzer
    data:
      provider: OpenAI
      model: gpt-4
      include_filename: false
      target_width: 1280
      detail: high
      max_tokens: 221
      temperature: 0.5
      image_entity:
        - !input camera_entity
      message: !input image_instructions
    response_variable: response
  - service: media_player.volume_set
    target:
      entity_id: !input media_player_entity
    data:
      volume_level: !input volume_level
  - service: tts.google_cloud_say
    data:
      entity_id: !input media_player_entity
      message: "{{ response.response_text }}"
      language: en-US
      options:
        gender: MALE
        voice: en-US-Casual-K
  - delay:
      seconds: !input delay_seconds  # Configurable delay
  - service: llmvision.image_analyzer  # Reprocess the image with new instructions after the delay
    data:
      provider: OpenAI
      model: gpt-4
      include_filename: false
      target_width: 1280
      detail: high
      max_tokens: 221
      temperature: 0.5
      image_entity:
        - !input camera_entity
      message: !input after_delay_instructions  # Use the configurable instructions after the delay

mode: single
